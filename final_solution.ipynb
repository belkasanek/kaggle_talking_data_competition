{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!pip3 install --upgrade pandas\n",
    "!pip3 install lightgbm\n",
    "!pip3 install bottleneck\n",
    "!pip3 install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%gcs read --object gs://kaggle_talkingdata_belkasanek/train.csv --variable train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "\n",
    "train_df = pd.read_csv(io.BytesIO(train), parse_dates=['click_time'], dtype=dtypes, \n",
    "                       usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n",
    "\n",
    "train_df['day'] = train_df['click_time'].dt.day.astype('uint8')\n",
    "train_df['hour'] = train_df['click_time'].dt.hour.astype('uint32')\n",
    "\n",
    "# train data contains day 6, 7, 8, 9 test data contains day 10\n",
    "# 6 day has small amount of data\n",
    "# test data include only hours 4, 5, 9, 10, 13, 14\n",
    "# but for purpose of feature engineering we will use bigger time frame\n",
    "train_df = train_df.loc[(train_df['day'] >= 7) & (train_df['hour'].between(2, 16))]\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def time_feature(train_df, columns, prefix='nc'):\n",
    "    ''' \n",
    "    Add new feature that is time to next or previous click in a particular group\n",
    "    If time is not exist fill it with value 65500\n",
    "    train_df - pd.DataFrame\n",
    "    columns - list of strings, used to make grouping\n",
    "    prefix - string, used to regulate next or previous click will be used \n",
    "    'pc' for precvous and 'nc' for next\n",
    "    '''\n",
    "\n",
    "    train_df = train_df.sort_values(by=columns + ['my_time'])\n",
    "    \n",
    "    new_feature = prefix + '_' + '_'.join(columns)\n",
    "    if prefix == 'pc':\n",
    "        n = 1\n",
    "        train_df[new_feature] = train_df['my_time'] - train_df['my_time'].shift(n)\n",
    "    if prefix == 'nc':\n",
    "        n = -1\n",
    "        train_df[new_feature] = train_df['my_time'].shift(n) - train_df['my_time']\n",
    "        \n",
    "    # create temporary columns with bool where some feature are changed\n",
    "    for col in columns:\n",
    "        train_df['temp_{}'.format(col)] = train_df[col] != train_df[col].shift(n)\n",
    "    # add their names to this list\n",
    "    bool_col = ['temp_' + i for i in columns]\n",
    "    \n",
    "    # fill with value 65500 where any feature are changed or NaN\n",
    "    train_df.loc[train_df[bool_col].any(axis=1), new_feature] = 65500\n",
    "    train_df.fillna(65500)\n",
    "    \n",
    "    train_df[new_feature] = train_df[new_feature].astype('uint16')\n",
    "    # drop temporary columns\n",
    "    train_df.drop(bool_col, axis=1, inplace=True)\n",
    "    gc.collect()\n",
    "    return train_df\n",
    "\n",
    "def time_feature_engineering(train_df):\n",
    "    '''\n",
    "    Create custom time 'my_time' because date is not need any more\n",
    "    Also create all time features\n",
    "    '''\n",
    "    \n",
    "    train_df['minute'] = train_df['click_time'].dt.minute\n",
    "    train_df['second'] = train_df['click_time'].dt.second\n",
    "    train_df['my_time'] = train_df['hour'] * 3600 + train_df['minute'] * 60 + train_df['second']\n",
    "\n",
    "    train_df['my_time'] = train_df['my_time'].astype('uint32')\n",
    "    train_df['hour'] = train_df['hour'].astype('uint8')\n",
    "\n",
    "    train_df.drop(['click_time', 'minute', 'second'], axis=1, inplace=True)\n",
    "  \n",
    "    train_df = time_feature(train_df, ['ip', 'os'], 'nc')\n",
    "    train_df = time_feature(train_df, ['ip', 'app'] , 'nc')\n",
    "    train_df = time_feature(train_df, ['ip', 'app', 'os'] , 'nc')\n",
    "    train_df = time_feature(train_df, ['app', 'channel'] , 'nc')\n",
    "    train_df = time_feature(train_df, ['ip'], 'nc')\n",
    "    train_df = time_feature(train_df, ['ip', 'os', 'device'], 'nc')\n",
    "    train_df = time_feature(train_df, ['ip', 'os', 'device', 'app'], 'nc')\n",
    "    train_df = time_feature(train_df, ['ip', 'channel'], 'nc')\n",
    "    return train_df\n",
    "  \n",
    "def feature_engineering(train_df):\n",
    "    '''\n",
    "    Create all non-time features\n",
    "    '''\n",
    "    \n",
    "    train_df= train_df.sort_values(by=['ip', 'my_time'])\n",
    "    train_df.drop(['my_time'], axis=1, inplace=True)\n",
    "   \n",
    "    # count of unique apps visited by user\n",
    "    train_df= train_df.assign(unique_app_ip=train_df[['ip', 'app']].groupby(by=['ip'])['app'].transform('nunique'))\n",
    "\n",
    "    # count of unique channels visited by user\n",
    "    train_df= train_df.assign(unique_channel_ip=train_df[['ip', 'channel']].groupby(by=['ip'])['channel']\\\n",
    "                              .transform('nunique'))    \n",
    "    \n",
    "    # cumcount of user with same device\n",
    "    train_df= train_df.assign(cumcount_ip_device=train_df[['ip', 'device', 'hour']]\\\n",
    "                   .groupby(by=['ip', 'device'])['hour'].cumcount().astype('uint32'))\n",
    "    \n",
    "    # cumcount of user with same device and os     \n",
    "    train_df= train_df.assign(cumcount_ip_os_device=train_df[['ip', 'os', 'device', 'hour']]\\\n",
    "                   .groupby(by=['ip', 'os', 'device'])['hour'].cumcount().astype('uint32'))\n",
    "    \n",
    "    # count of unique os for app\n",
    "    train_df= train_df.assign(unique_os_app=train_df[['app', 'os']].groupby(by='app')['os'].transform('nunique'))\n",
    "\n",
    "    # count of clicks on app for user\n",
    "    train_df= train_df.assign(count_ip_app=train_df[['ip', 'app', 'hour']]\\\n",
    "                   .groupby(by=['ip', 'app'])['hour'].transform('count').astype('uint16'))\n",
    "\n",
    "    # mean click rate on apps for user\n",
    "    train_df= train_df.assign(mean_ip_app=train_df[['ip', 'count_ip_app']]\\\n",
    "                   .groupby(by='ip')['count_ip_app'].transform('mean').astype('uint16'))\n",
    "    \n",
    "    # count of clicks for user with defined os and device\n",
    "    train_df= train_df.assign(count_ip_os_device=train_df[['ip', 'os', 'device', 'hour']]\\\n",
    "               .groupby(by=['ip', 'os', 'device'])['hour'].transform('count').astype('uint16'))\n",
    "    \n",
    "    # count of clicks for user with defined app, os and device\n",
    "    train_df= train_df.assign(count_ip_app_os_device=train_df[['ip', 'app', 'os', 'device', 'hour']]\\\n",
    "           .groupby(by=['ip', 'app', 'os', 'device'])['hour'].transform('count').astype('uint16'))\n",
    "\n",
    "    # count of unique channels for ip and app\n",
    "    train_df= train_df.assign(unique_channel_ip_app=train_df[['ip', 'app', 'channel']]\\\n",
    "                   .groupby(by=['ip', 'app'])['channel'].transform('nunique'))\n",
    "    \n",
    "    # hour with maximum user's activity\n",
    "    train_df= train_df.assign(max_hour_ip=train_df[['ip', 'hour']].groupby(by=['ip'])['hour']\\\n",
    "                   .transform(lambda x: np.bincount(x).argmax()).astype('uint8'))\n",
    "    \n",
    "    # channel that most used by user\n",
    "    train_df= train_df.assign(max_channel_ip=train_df[['ip', 'channel']].groupby(by=['ip'])['channel']\\\n",
    "                   .transform(lambda x: np.bincount(x).argmax()).astype('uint16'))\n",
    "\n",
    "    # count of total clicks by user\n",
    "    train_df= train_df.assign(count_ip=train_df[['ip', 'hour']].groupby(by='ip')['hour']\\\n",
    "                              .transform('count').astype('uint32'))\n",
    "    \n",
    "    # count of total clicks through channel\n",
    "    train_df= train_df.assign(count_channel=train_df[['channel', 'ip']].groupby(by='channel')['ip']\\\n",
    "                              .transform('count').astype('uint16'))\n",
    "    \n",
    "    categorical_features = ['app', 'device', 'os', 'channel', 'hour', \n",
    "                            'max_hour_ip', 'max_channel_ip']\n",
    "    \n",
    "    for i in categorical_features:\n",
    "        train_df[i] = train_df[i].astype('category')\n",
    "        \n",
    "    train_df.drop(['ip'], axis=1, inplace=True)\n",
    "    gc.collect()\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# feature engineering on every day independently\n",
    "day7 = train_df.loc[(train_df['day'] == 7)].copy()\n",
    "train_df = train_df.loc[train_df['day'] != 7]\n",
    "day8 = train_df.loc[(train_df['day'] == 8)].copy()\n",
    "train_df = train_df.loc[train_df['day'] != 8]\n",
    "day9 = train_df.loc[(train_df['day'] == 9)].copy()\n",
    "\n",
    "day7.drop(['day'], axis=1, inplace=True)\n",
    "day8.drop(['day'], axis=1, inplace=True)\n",
    "day9.drop(['day'], axis=1, inplace=True)\n",
    "del train_df\n",
    "gc.collect()\n",
    "\n",
    "day7 = time_feature_engineering(day7)\n",
    "day8 = time_feature_engineering(day8)\n",
    "day9 = time_feature_engineering(day9)\n",
    "\n",
    "day7 = feature_engineering(day7)\n",
    "day8 = feature_engineering(day8)\n",
    "day9 = feature_engineering(day9)\n",
    "\n",
    "train_df = pd.concat([day7, day8, day9])\n",
    "del day7, day8, day9\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make validation set\n",
    "predictors = train_df.columns.tolist()\n",
    "predictors.remove('is_attributed')\n",
    "\n",
    "ratio_valid_set = 0.1\n",
    "# most used hours in test data\n",
    "most_hour = [4, 5, 9, 10, 13, 14]\n",
    "\n",
    "tr = train_df.loc[~train_df['hour'].isin(most_hour)]\n",
    "temp = train_df.loc[train_df['hour'].isin(most_hour)]\n",
    "\n",
    "temp = temp.sample(frac=1)\n",
    "n = temp.shape[0]\n",
    "\n",
    "val_df = temp[(int(n)-int(n * ratio_valid_set)):int(n)]\n",
    "train_df = tr.append(temp[:(int(n)-int(n * ratio_valid_set))])\n",
    "train_df = train_df.sample(frac=1)\n",
    "\n",
    "del tr, temp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "categorical_features = ['app', 'device', 'os', 'channel', 'hour', \n",
    "                        'max_hour_ip', 'max_channel_ip']\n",
    "lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric':'auc',\n",
    "        'subsample_for_bin': 20000,\n",
    "        'reg_alpha': 0.2,\n",
    "        'reg_lambda': 0.1,\n",
    "        'nthread': 16,\n",
    "        'verbose': 0\n",
    "    }\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 25,\n",
    "    'max_depth': 4,\n",
    "    'min_child_samples': 75,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 1,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'scale_pos_weight': 200\n",
    "}\n",
    "num_boost_round = 1000\n",
    "early_stopping_rounds = 30\n",
    "\n",
    "lgb_params.update(params)\n",
    "\n",
    "xgtrain = lgb.Dataset(train_df[predictors], \n",
    "                      label=train_df['is_attributed'].values,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical_features\n",
    "                      )\n",
    "xgvalid = lgb.Dataset(val_df[predictors], \n",
    "                      label=val_df['is_attributed'].values,\n",
    "                      feature_name=predictors,\n",
    "                      categorical_feature=categorical_features\n",
    "                      )\n",
    "\n",
    "evals_results = {}\n",
    "\n",
    "bst1 = lgb.train(lgb_params, \n",
    "                 xgtrain, \n",
    "                 valid_sets=[xgvalid], \n",
    "                 valid_names=['valid'], \n",
    "                 evals_result=evals_results, \n",
    "                 num_boost_round=num_boost_round,\n",
    "                 early_stopping_rounds=early_stopping_rounds,\n",
    "                 verbose_eval=10,\n",
    "                 feature_name=predictors,\n",
    "                 categorical_feature=categorical_features\n",
    "                )\n",
    "\n",
    "print(\"\\nModel Report\")\n",
    "print(\"bst1.best_iteration: \", bst1.best_iteration)\n",
    "print(\"auc: {:.4f}\".format(evals_results['valid']['auc'][bst1.best_iteration-1]))\n",
    "best_iteration = bst1.best_iteration-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del train_df, val_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%gcs read --object gs://kaggle_talkingdata_belkasanek/mapping.csv --variable mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%gcs read --object gs://kaggle_talkingdata_belkasanek/test_supplement.csv --variable test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# feature engineering on test data\n",
    "train_df = pd.read_csv(io.BytesIO(test), parse_dates=['click_time'], dtype=dtypes, \n",
    "                      usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'click_id'])\n",
    "\n",
    "del test\n",
    "gc.collect()\n",
    "\n",
    "mapping = pd.read_csv(io.BytesIO(mapping), dtype={'click_id': 'int32', 'old_click_id': 'int32'})\n",
    "\n",
    "train_df.rename(columns={'click_id': 'old_click_id'}, inplace=True)\n",
    "train_df = pd.merge(train_df, mapping, on=['old_click_id'], how='left')\n",
    "train_df.drop(['old_click_id'], axis=1, inplace=True)\n",
    "train_df['click_id'].fillna(-1, inplace=True)\n",
    "train_df['click_id'] = train_df['click_id'].astype(np.int32)\n",
    "train_df['hour'] = train_df['click_time'].dt.hour.astype('uint32') \n",
    "\n",
    "train_df = time_feature_engineering(train_df)\n",
    "train_df = feature_engineering(train_df)\n",
    "\n",
    "train_df = train_df.loc[train_df['click_id'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = train_df['click_id']\n",
    "sub['click_id'] = sub['click_id'].astype('int')\n",
    "sub['is_attributed'] = bst1.predict(train_df[predictors], num_iteration=best_iteration)\n",
    "sub.to_csv('final.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil cp final.csv.gz gs://kaggle_talkingdata_belkasanek/final.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del train_df, sub\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
